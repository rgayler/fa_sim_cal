---
title: "02-2_mk_block_vars"
subtitle: "Make blocking variables"
author: "Ross Gayler"
date: "2021-01-24"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup}
# Set up the project environment, because each Rmd file knits in a new R session
# so doesn't get the project setup from .Rprofile

# Project setup
library(here)
source(here::here("code", "setup_project.R"))

# Extra set up for the 02*.Rmd notebooks
source(here::here("code", "setup_02.R"))

# Extra set up for this notebook
# ???

# start the execution time clock
tictoc::tic("Computation time (excl. render)")
```

# Introduction

This notebook (`02-2_mk_block_vars`) constructs the potential blocking
variables identified in the previous notebook:

-   (sex, age)
-   (age, county)
-   (sex, age, county)

Show the assumed range of useful block sizes.

```{r}
# Arbitrary lower and upper bound on useful block size
# These are set in setup_02.R
blk_sz_min
blk_sz_max
```

# Read data

Read the usable data. Remember that this consists of only the ACTIVE &
VERIFIED records.

```{r}
# Show the entity data file location
# This is set in code/file_paths.R
fs::path_file(f_entity_cln_fst)

# get entity data
d <- fst::read_fst(
  f_entity_cln_fst,
  columns = c("id", "sex", "age_cln", "age_cln_miss", "birth_place", "county_id")
  ) %>% 
  tibble::as_tibble()

dim(d)
```

# Missing values

Identify the missing values in the blocking variables and flag those
records as exclusions for blocking and modelling.

Sex and age have missing values, county ID does not.

```{r}
# updating d is probably poor form
# but I am only adding variables, so it is idempotent
d <- d %>% 
  dplyr::mutate(
    excl_blk_age_county_miss = age_cln_miss,
    excl_blk_sex_age_miss = sex == "UNK" | age_cln_miss,
    excl_blk_sex_age_county_miss = sex == "UNK" | age_cln_miss
  )

d %>% 
  dplyr::select(starts_with("excl_blk_")) %>% 
  summary()
```

-   (age, county) excludes \~31k (\~0.8%) of records from blocking and
    modelling.
-   (sex, age) and (sex, age, county) excludes \~47k (\~1.1%) of records
    from blocking and modelling.

# (sex, age)

There are only 4 blocks in (sex, age) that are too small. This can be
fixed with a small amount of age pooling.

The 17 year old and oldest age groups are the smallest, so they will
need pooling with other age groups.

The ordering of age is meaningful, so only pool adjacent ages (in order
to maintain the meaningfulness of the ordering).

Age will be combined with sex, so it is the size of the combined (sex,
age) blocks which is relevant.

The distribution of age is likely to be different for males and females.
We could have different pooling of age for males and females. However,
for simplicity I will use the same pooling of age for males and females.

Look at the distribution of block sizes for the relevant age groups.

```{r}
d %>% 
  dplyr::filter(!excl_blk_sex_age_miss &
                  (age_cln <= 20 | age_cln >= 95)) %>%
  with(table(age_cln, sex))
```

-   Pool the 17 year olds with the 18 year olds

-   Pooling 102 with 103 would be adequate.

    -   However the spikes of records at 101 and 104 are somewhat
        suspect. So I will pool all the records with ages over 100 in
        order to put all the questionable records in the one block.

Characterise the newly constructed (sex, age) blocking variable.

```{r}
# construct the (sex, age) blocking variable

# updating d is probably poor form
# but I am only adding variables, so it is idempotent
d <- d %>% 
  dplyr::mutate(
    blk_age = dplyr::case_when(
      excl_blk_sex_age_miss  ~ NA_integer_, # make value NA for safety
      # code using NA is likely to fail if I forget to exclude these cases
      age_cln == 17          ~ 18L, # map 17 to 18
      age_cln >= 101         ~ 101L, # map all ages >= 101 to 101
      TRUE                   ~ age_cln # all ages < 101, accept as is
    ),
    # create the new combined blocking variable
    blk_sex_age = dplyr::if_else(excl_blk_sex_age_miss,
                                 NA_character_, # make value NA for safety
                                 paste0("Sex=", sex,  ":AgeGrp=", blk_age)
    )
  ) %>% 
  dplyr::select(-blk_age) # we won't use age alone as a blocking variable

# calculate the distribution of block sizes
d_blk <- d %>% 
  dplyr::filter(!excl_blk_sex_age_miss) %>% 
  dplyr::count(blk_sex_age, name = "blk_sz") 

# number of blocks
nrow(d_blk)

# summary of distribution of block sizes
summary(d_blk$blk_sz)

# distribution of block sizes
d_blk %>% 
  ggplot(aes(x = blk_sz)) +
  geom_vline(xintercept = c(blk_sz_min, blk_sz_max), colour = "blue") +
  # geom_jitter(width = 0.35, alpha = 0.2) +
  geom_histogram(bins = 10, boundary = log10(blk_sz_max), alpha = 0.5) +
  geom_rug(colour = "dark grey", alpha = 0.5) +
  geom_boxplot(outlier.shape = NA, colour = "red", alpha = 0, size = 1, width = 5) +
  scale_x_log10(n.breaks = 7) + annotation_logticks(sides = "b") +
  theme(panel.grid.minor.x = element_blank()) + 
  xlab("Block size (records)") + ylab("Count (blocks)")
```

-   168 blocks

-   100% of blocks in the useful size range and covering most of the
    range

    -   Minimum block size: 95 records
    -   Maximum block size: 47,190 records

-   Mean block size (most relevant for computational effort): \~24k
    records

-   The block sizes are concentrated at the higher end of the range (on
    a logarithmic size scale)

# (age, county)

There are 1,759 (21%) blocks in (age, county) that are too small. None
are too large and the largest block is significantly smaller than the
upper bound on useful block size. I hope this can be fixed with some
aggressive pooling.

Both age and county are able to be pooled. The ordering of age is
meaningful so it makes most sense to pool adjacent age values to
maintain the ordering. The county IDs are not ordered, so there is no
obvious constraint on which counties should be pooled.

Prefer to pool age because the basis of pooling is clear. The fraction
of records at each age is never large, so we have good control over the
boundaries between pooled ages.

```{r}
# get the block sizes for age and county in isolation
d_blk_age <- d %>% 
  dplyr::filter(!excl_blk_age_county_miss) %>% 
  dplyr::count(age_cln, name = "blk_sz") 

d_blk_cnty <- d %>% 
  dplyr::filter(!excl_blk_age_county_miss) %>% 
  dplyr::count(county_id, name = "blk_sz") 

# summaries of block sizes for age and county in isolation
summary(d_blk_age$blk_sz)
summary(d_blk_cnty$blk_sz)
```

For county ID, the maximum block size is 410,466 records and the minimum
block size is 1,027 records.

-   To reduce the maximum block size to 50k records we need to combine
    it with an age group with no more than 50,000 / 410,466 =
    `r floor(100 * 50e3 / 410466)`% of the records.

-   To reduce the minimum block size to 50 records we need to combine it
    with an age group with no less than 50 / 1,027 =
    `r ceiling(100 * 50 / 1027)`% of the records.

-   The previous points assume that age and county are independent,
    which is unlikely to be exactly true. So the figures calculated here
    should be regarded as back of the envelope approximations.

-   The largest pooled age group is 12% of records and the smallest is
    5%. That leaves 83% of the records to be distributed over the pooled
    groups of intermediate size.

    -   The intermediate pooled groups can't be larger than the largest
        group, so there must be at least ceiling(83 / 12) =
        `r ceiling(83/12)` intermediate groups.
    -   The intermediate pooled groups can't be smaller than the
        smallest group, so there must be no more than floor(83 / 5) =
        `r floor(83/5)` intermediate groups.

-   So, there must be between 5 and 16 intermediate pooled age groups.

    -   Use 10 intermediate groups because experimentation shows this
        gives pleasing results with the following code.

-   Aim for the intermediate group sizes to be equally spaced on a
    linear probability scale between the sizes of the largest and
    smallest pooled groups.

    -   The age groups are smaller for the higher ages, so make the
        smallest pooled age group correspond to the highest ages to
        provide finer control of the pooled group boundaries where the
        pooled groups are smallest.

The target boundaries for the age groups are calculated as follows:

```{r}
n_grp <- 10 + 1 + 1 # 10 intermediate + 1 largest + 1 smallest

n_rec <- sum(d_blk_age$blk_sz) # number of records

p_max <- 0.12 # fraction of records in largest group
p_min <- 0.05 # fraction of records in smallest group

groups <- tibble::tibble(
  grp = 1:n_grp
)

groups <- groups %>% 
  dplyr::mutate(
    p_raw = # raw fraction of records in each group (do NOT sum to 1)
      seq(from = p_max, to = p_min, length.out = n_grp), # intermediate probs equally spaced on linear scale
    
    p_grp = # fraction of records in each group (normalised to sum to 1)
      dplyr::if_else(grp %in% c(1, n_grp),
                     p_raw,
                     (1.0 - (p_max + p_min)) * p_raw / (sum(p_raw) - (p_max + p_min))
      ),
    
    p_cum = # cumulative fraction of records at the top boundary of each group
      cumsum(p_grp),
    
    rec_cut = # nearest record to group boundary
      round(p_cum * n_rec)
  )

# look at the results of the group size calculation
groups %>% 
  knitr::kable(format.args = list(big.mark = ","))
```

Now construct functions to map from age to pooled age group.

```{r}
# map from cumulative record number to group number
cumrec_to_grp <- stepfun(
  x = c(1L, groups$rec_cut), # x value is the upper/right boundary of each group
  y = c(1L, 1L, groups$grp),
  right = FALSE,
  f = 1 # use the x value to the right when interpolating
)

cumrec_to_grp

# add group number to the blocked age
d_blk_age <- d_blk_age %>% 
  dplyr::mutate(
    cum_rec = cumsum(blk_sz),
    grp = cumrec_to_grp(cum_rec)
  )

# map from age to group number
age_to_grp <- stepfun(
  x = c(16L, d_blk_age$age_cln), # x value is the upper/right boundary of each group
  y = c(1L, 1L, d_blk_age$grp),
  right = FALSE,
  f = 1 # use the x value to the right when interpolating
)

age_to_grp

# add mapped group number to the blocked age to check
d_blk_age <- d_blk_age %>% 
  dplyr::mutate(
    grp_from_age = age_to_grp(age_cln)
  )
```

Construct the (age, county) blocking variable.

```{r}
# construct the (age, county) blocking variable

# updating d is probably poor form
# but I am only adding variables, so it is idempotent
d <- d %>% 
  dplyr::mutate(
    # create the new combined blocking variable
    blk_age_county = dplyr::if_else(excl_blk_age_county_miss,
                                    NA_character_, # make value NA for safety
                                    paste0("AgeGrp=", age_to_grp(age_cln), ":County=", county_id)
    )
  )
```

Characterise the newly constructed (age, county) blocking variable.

```{r}
# calculate the distribution of block sizes
d_blk <- d %>% 
  dplyr::filter(!excl_blk_age_county_miss) %>% 
  dplyr::count(blk_age_county, name = "blk_sz") 

# number of blocks
nrow(d_blk)

# summary of distribution of block sizes
summary(d_blk$blk_sz)

# distribution of block sizes
d_blk %>% 
  ggplot(aes(x = blk_sz)) +
  geom_vline(xintercept = c(blk_sz_min, blk_sz_max), colour = "blue") +
  # geom_jitter(width = 0.35, alpha = 0.2) +
  geom_histogram(bins = 20, boundary = log10(blk_sz_max), alpha = 0.5) +
  geom_rug(colour = "dark grey", alpha = 0.5) +
  geom_boxplot(outlier.shape = NA, colour = "red", alpha = 0, size = 1, width = 5) +
  scale_x_log10(n.breaks = 7) + annotation_logticks(sides = "b") +
  theme(panel.grid.minor.x = element_blank()) + 
  xlab("Block size (records)") + ylab("Count (blocks)")
```

-   1200 blocks

-   \~99.8%% of blocks in the useful size range and covering the entire
    useful range

    -   Only two blocks just outside the useful block size range
    -   Minimum block size: 44 records
    -   Maximum block size: 54,013 records

-   Mean block size (most relevant for computational effort): \~3.4k
    records

-   The block sizes are concentrated in the middle of the useful range
    (on a logarithmic size scale)

    -   Median block size \~1.8k records

# (sex, age, county)

There are 5,127 (31%) blocks in (sex, age, county) that are too small.
None are too large and the largest block is significantly smaller than
the upper bound on useful block size. I hope this can be fixed with some
aggressive pooling.

Both age and county are able to be pooled. The ordering of age is
meaningful so it makes most sense to pool adjacent age values to
maintain the ordering. The county IDs are not ordered, so there is no
obvious constraint on which counties should be pooled.

Prefer to pool age because the basis of pooling is clear. The fraction
of records at each age is never large, so we have good control over the
boundaries between pooled ages.

```{r}
# get the unpooled block sizes for (sex, age, county), (sex, age), age, and county
d_blk_sex_age_county <- d %>% 
  dplyr::filter(!excl_blk_sex_age_county_miss) %>% 
  dplyr::count(sex, age_cln, county_id, name = "blk_sz") 
summary(d_blk_sex_age_county$blk_sz)

d_blk_sex_county <- d %>% 
  dplyr::filter(!excl_blk_sex_age_county_miss) %>% 
  dplyr::count(sex, county_id, name = "blk_sz") 
summary(d_blk_sex_county$blk_sz)
```

For (sex, county), the maximum block size is 226,197 records and the minimum
block size is 435 records.

-   To reduce the maximum block size to 50k records we need to combine
    it with an age group with no more than 50,000 / 226,197 =
    `r floor(100 * 50e3 / 226197)`% of the records.

-   To reduce the minimum block size to 50 records we need to combine it
    with an age group with no less than 50 / 435 =
    `r ceiling(100 * 50 / 435)`% of the records.
    
-   The previous points assume that sex, age, and county are independent,
    which is unlikely to be exactly true. So the figures calculated here
    should be regarded as back of the envelope approximations.

-   The largest pooled age group is 22% of records and the smallest is
    12%. That leaves 66% of the records to be distributed over the pooled
    groups of intermediate size.

    -   The intermediate pooled groups can't be larger than the largest
        group, so there must be at least ceiling(66 / 22) =
        `r ceiling(66/22)` intermediate groups.
    -   The intermediate pooled groups can't be smaller than the
        smallest group, so there must be no more than floor(66 / 12) =
        `r floor(66/12)` intermediate groups.

-   So, there must be between 3 and 5 intermediate pooled age groups.

    -   Use 10 intermediate groups because experimentation shows this
        gives pleasing results with the following code.

-   Aim for the intermediate group sizes to be equally spaced on a
    linear probability scale between the sizes of the largest and
    smallest pooled groups.

    -   The age groups are smaller for the higher ages, so make the
        smallest pooled age group correspond to the highest ages to
        provide finer control of the pooled group boundaries where the
        pooled groups are smallest.

The target boundaries for the age groups are calculated as follows:

```{r}
n_grp <- 4 + 1 + 1 # 10 intermediate + 1 largest + 1 smallest

n_rec <- sum(d_blk_age$blk_sz) # number of records

p_max <- 0.22 # fraction of records in largest group
p_min <- 0.12 # fraction of records in smallest group

groups <- tibble::tibble(
  grp = 1:n_grp
)

groups <- groups %>% 
  dplyr::mutate(
    p_raw = # raw fraction of records in each group (do NOT sum to 1)
      seq(from = p_max, to = p_min, length.out = n_grp), # intermediate probs equally spaced on linear scale
    
    p_grp = # fraction of records in each group (normalised to sum to 1)
      dplyr::if_else(grp %in% c(1, n_grp),
                     p_raw,
                     (1.0 - (p_max + p_min)) * p_raw / (sum(p_raw) - (p_max + p_min))
      ),
    
    p_cum = # cumulative fraction of records at the top boundary of each group
      cumsum(p_grp),
    
    rec_cut = # nearest record to group boundary
      round(p_cum * n_rec)
  )

# look at the results of the group size calculation
groups %>% 
  knitr::kable(format.args = list(big.mark = ","))
```

Now construct functions to map from age to pooled age group.

```{r}
# map from cumulative record number to group number
cumrec_to_grp <- stepfun(
  x = c(1L, groups$rec_cut), # x value is the upper/right boundary of each group
  y = c(1L, 1L, groups$grp),
  right = FALSE,
  f = 1 # use the x value to the right when interpolating
)

cumrec_to_grp

# add group number to the blocked age
d_blk_age <- d_blk_age %>% 
  dplyr::mutate(
    cum_rec = cumsum(blk_sz),
    grp = cumrec_to_grp(cum_rec)
  )

# map from age to group number
age_to_grp <- stepfun(
  x = c(16L, d_blk_age$age_cln), # x value is the upper/right boundary of each group
  y = c(1L, 1L, d_blk_age$grp),
  right = FALSE,
  f = 1 # use the x value to the right when interpolating
)

age_to_grp

# add mapped group number to the blocked age to check
d_blk_age <- d_blk_age %>% 
  dplyr::mutate(
    grp_from_age = age_to_grp(age_cln)
  )
```

Construct the (age, county) blocking variable.

```{r}
# construct the (age, county) blocking variable

# updating d is probably poor form
# but I am only adding variables, so it is idempotent
d <- d %>% 
  dplyr::mutate(
    # create the new combined blocking variable
    blk_sex_age_county = dplyr::if_else(excl_blk_sex_age_county_miss,
                                    NA_character_, # make value NA for safety
                                    paste0("Sex=", sex, ":AgeGrp=", age_to_grp(age_cln), ":County=", county_id)
    )
  )
```

Characterise the newly constructed (age, county) blocking variable.

```{r}
# calculate the distribution of block sizes
d_blk <- d %>% 
  dplyr::filter(!excl_blk_sex_age_county_miss) %>% 
  dplyr::count(blk_sex_age_county, name = "blk_sz") 

# number of blocks
nrow(d_blk)

# summary of distribution of block sizes
summary(d_blk$blk_sz)

# distribution of block sizes
d_blk %>% 
  ggplot(aes(x = blk_sz)) +
  geom_vline(xintercept = c(blk_sz_min, blk_sz_max), colour = "blue") +
  # geom_jitter(width = 0.35, alpha = 0.2) +
  geom_histogram(bins = 20, boundary = log10(blk_sz_max), alpha = 0.5) +
  geom_rug(colour = "dark grey", alpha = 0.5) +
  geom_boxplot(outlier.shape = NA, colour = "red", alpha = 0, size = 1, width = 5) +
  scale_x_log10(n.breaks = 7) + annotation_logticks(sides = "b") +
  theme(panel.grid.minor.x = element_blank()) + 
  xlab("Block size (records)") + ylab("Count (blocks)")
```

-   1200 blocks

-   \~99.8%% of blocks in the useful size range and covering the entire
    useful range

    -   Only two blocks lie just outside the useful block size range
    -   Minimum block size: 45 records
    -   Maximum block size: 51,009 records

-   Mean block size (most relevant for computational effort): \~3.4k
    records

-   The block sizes are concentrated in the middle of the useful range
    (on a logarithmic size scale)

    -   Median block size \~1.8k records

# Save enity blocking variables

Save the blocking variables as a separate file that can be joined to the clean entity data.

```{r}
# Show the clean data file location
# This is set in code/file_paths.R
fs::path_file(f_entity_blk_fst)

# save the entity blocking variables (cheap-skate caching)
d %>% 
  dplyr::select(id, starts_with(c("excl_blk_", "blk_"))) %>% 
  fst::write_fst(f_entity_blk_fst, compress = 100) %>% 
  dplyr::glimpse()
```

# Characterise the blocks

Characterise the blocks. This may be useful later for selecting the blocks to use.

```{r}
# function to characterise the contents of 1 block
char_1_block <- function(
  .x, # data frame containing all the records of one block
  .y  # one-row data frame - the grouping key (must be one-column only)
  # value: a data frame of one row giving all the summary statistics for the block
) {
  tibble::tibble(
    blk_id = .y[[1]],
    blk_sz = nrow(.x),
    sex_p_female = sum(.x$sex == "FEMALE") / blk_sz,
    sex_n = .x$sex %>% unique() %>% length(),
    sex_n_eff = .x$sex %>% n_eff(),
    age_mean = mean(.x$age_cln),
    age_min = min(.x$age_cln),
    age_max = max(.x$age_cln),
    age_range = age_max - age_min + 1,
    county_n = .x$county_id %>% unique() %>% length(),
    county_n_eff = .x$county_id %>% n_eff()
  )
}

# Function to calculate the effective number of levels of a categorical variable
# Based on Shannon entropy
# This is the number of levels a uniformly distributed variable would need to have the same entropy
n_eff <- function (
  x # vector of discrete levels
) {
  p <- table(x) %>% prop.table() %>% as.vector() # probabilities of levels
  -sum( p * log(p)) %>% exp()
}

# characterise each of the blocks created by each of the blocking variables
# and put all the results in a single data frame
d_blks <- dplyr::bind_rows(
  list(
    blk_sex_age = d %>% 
      dplyr::filter(!excl_blk_sex_age_miss) %>% 
      dplyr::group_by(blk_sex_age) %>% 
      group_modify(char_1_block) %>% 
      dplyr::ungroup() %>% 
      dplyr::select(-blk_sex_age),
    
    blk_age_county = d %>% 
      dplyr::filter(!excl_blk_age_county_miss) %>% 
      dplyr::group_by(blk_age_county) %>% 
      group_modify(char_1_block) %>% 
      dplyr::ungroup() %>% 
      dplyr::select(-blk_age_county),
    
    blk_sex_age_county = d %>% 
      dplyr::filter(!excl_blk_sex_age_county_miss) %>% 
      dplyr::group_by(blk_sex_age_county) %>% 
      group_modify(char_1_block) %>% 
      dplyr::ungroup() %>% 
      dplyr::select(-blk_sex_age_county)
  ),
  .id = "blk_var"
)
```

# Save the block characterisations

Save the characterisation of each block created by each blocking variable.

```{r}
# Show the clean data file location
# This is set in code/file_paths.R
fs::path_file(f_blk_char.fst)

# save the entity blocking variables (cheap-skate caching)
d_blks %>% 
  fst::write_fst(f_blk_char.fst, compress = 100) %>% 
  dplyr::glimpse()
```

# Timing {.unnumbered}

```{r echo=FALSE}
tictoc::toc()
```
