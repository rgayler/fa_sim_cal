---
title: "Workflow management"
author: "Ross Gayler"
# date: "2021-05-27"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, echo = FALSE}
# Don't echo the chunk code in these notes
knitr::opts_chunk$set(echo = FALSE)

library(DiagrammeR)
```

This project uses the [`targets`](https://wlandau.github.io/targets/)
and [`workflowr`](https://github.com/jdblischak/workflowr) packages for
managing the workflow of the project (making sure that the dependencies
between computational steps are satisfied). When this work was started
there were no easily found examples of using `targets` and `workflowr`
together. This notebook contains notes on the proposed workflow for
using `targets` and `workflowr`.

# Assumptions

These points reflect my (possibly faulty) understanding of `targets` and
`workflowr`. If I am wrong here I hope that somebody will see this and
let me know, rather than me having to find out the hard way.

-   `targets` and `workflowr` both work by tracking some set of entities
    and the computational dependencies between them. When any of the
    tracked entities changes, the packages calculate the minimal set of
    downstream dependencies that need to be recomputed to bring all the
    entities into a consistent state of being up to date.

-   `targets`

    -   Supports a computational-pipeline-centric style of analysis

    -   Tracks data objects (including files) and functions.

    -   The focus is on the data transformation by the computational
        pipeline (rather than human generated text in reports).

        -   Although reports can be rendered, they appear to be treated
            as optional final steps (like generating a plot), rather
            than as a core concern.
        -   That's quite reasonable because the output of a
            report-generating step will be a document or image that's
            very unlikely to be the input to another computational step.
            So reports are necessarily leaves on the computation graph.

    -   Knows about high-performance computing and can run computations
        in parallel.

-   `workflowr`

    -   Supports a notebook-centric style of analysis

    -   Only tracks Rmd notebook files and the corresponding rendered
        output files
        (<https://github.com/ropensci/tarchetypes/issues/23#issuecomment-749118599>)

        -   `workflowr::wflow_build()` tracks modification dates of Rmd
            files and the corresponding rendered output files

        -   `workflowr::wflow_publish()` tracks git status of Rmd files
            and the corresponding rendered output files

            -   The decision to publish the analyses seems necessarily
                manual to me.

        -   The computational consistency aspect are really only about
            the consistency between the notebook Rmd files and their
            rendered counterparts. That is, \`workflowr\` really only
            knows about notebook rendering and not about the
            computations in those notebooks.

    -   The computational reproducibility aspect is restricted to
        ensuring that random number seeds are set appropriately, that
        each notebook is executed in a clean environment, and that the
        package versions are recorded

    -   Automatic building of a website for the rendered notebooks

    -   Publication of website integrated with git

    -   Automatic publication of website served by GitHub Pages

-   Comparison of `targets` and `workflowr`

    -   `targets` provides more general and fine-grained control of the
        computational pipeline

        -   Rendering of Rmd documents can be treated as just another
            step in a `targets` computational pipeline
        -   I would prefer to have computational dependency tracking
            handled by one package rather than splitting responsibility
            across multiple packages
        -   If I am going to use only one package to handle
            computational dependency tracking then I think it has to be
            `targets`

    -   If I use `targets` to manage computational dependency tracking,
        what extra capabilities does `workflowr` provide?

        -   Automatic generation of a website of rendered notebooks
        -   Automatic publication of the website via GitHub pages
            (provided you use GitHub as the git remote repository).
        -   I want this project to be publicly accessible and I don't
            want the trouble of having to manually generate a website,
            so I will use `workflowr` to handle the building and
            publication of the project website.

-   Design states and design reasoning

    -   The design state of the computational pipeline (loosely defined)
        reflects the *current* best beliefs. That is, any previous
        design states are believed to be flawed in some way and the
        current design state is believed to be better.

    -   While the system is being modified from the prior design state
        to the current design state it is transiently broken and there
        is no need for that broken state to be preserved and easily
        accessible later.

    -   Prior design states of the computational are not very
        interesting (because they are believed to be worse than the
        current design state) so there is no need for prior design
        states to be preserved and easily accessible later.

    -   The reasoning behind the current design state is important and
        must be preserved and immediately accessible.

    -   The reasoning behind the current design state *may* involve
        reference to prior design states and prior design reasoning.
        Where these references are needed they are included directly in
        the design reasoning for the current design state and are
        preserved and immediately accessible.

        -   The design reasoning consists of manually constructed text,
            possibly supported by specific analyses of data derived from
            the computational pipeline.

# Proposed workflow

-   The proposed workflow needs to support my preferences for how to
    organise a project. In particular, a computational research project
    necessarily involves many design choices for the computational
    details. It is my strong preference that the *reasoning* behind
    these design choices (which *may* involve additional empirical work
    to support the reasoning) is documented as part of the project.

-   The total workflow of the project has multiple components:

    -   **core** - This is the workflow that generates the primary
        computational outputs (data sets, tables, plots, etc.) of the
        project. None of the outputs of this workflow include manual
        interpretation. The transformations are purely mechanical and
        can be repeated automatically.
    -   **publications** - These are documents (manuscripts,
        presentations, etc.) that interpret the results of the core for
        some audience. These should be construed as the principal
        outputs of the core but they are treated separately because they
        necessarily involve interpretation which cannot be automated.
        The computation which generates the publications can be
        automated, but it can't automatically update the interpretations
        in the publications.
    -   **meta** - These are computations and interpretations that are
        *about* the core, but not required by the core. This where the
        design reasoning lives.

-   The core is implemented as a standard `targets` computational
    pipeline.

-   The publications are implemented as extensions to the core pipeline.

    -   There may be computational steps to generate data objects needed
        specifically for publications (e.g. plots and tables).
    -   It is recommended that computation in Rmd documents is
        minimised.
    -   The publications are plain Rmd documents (not `workflowr`
        notebooks).
    -   The publication-specific data objects and the rendering of the
        Rmd documents are managed by `targets`.

-   The meta components are implemented as short chains hanging off the
    core pipeline.

    -   There may be computational steps to generate data objects needed
        specifically for meta documents.

        -   These computational steps are managed by `targets`, so
            resulting data objects will be cached by `targets`.

    -   However, there is less pressure to minimise computation in the
        Rmd documents, because individual design decisions are less
        likely to need re-execution than the calculations on the core
        pipeline

    -   The meta publications are `workflowr` Rmd notebooks.

    -   The meta-specific data objects and the rendering of the Rmd
        documents are managed by `targets`.

    -   The meta documents are rendered to a `workflowr` website.

    -   The `workflowr` website also has links to the rendered
        publications.

    -   `workflowr` istinguished between building and publishing
        documents.

        -   The decision to publish is inherently manual, so building
            isinvoked from `targets` whereas publishing is only invoked
            manually.

An example is summarised in the following diagram.

```{r workflow_diagram, fig.asp = 1.4}
DiagrammeR::grViz("
digraph workflow_diagram {

node [fixedsize = true, fontsize = 6, style = filled]

### CORE
subgraph cluster_core {
  rank = same

  node [fillcolor = red]

  # data object nodes
  node [shape = circle]
  d_c1 [label = 'core\ndata 1']
  d_c2 [label = 'core\ndata 2']
  d_c3 [label = 'core\ndata 3']

  # function nodes
  node [shape = triangle]
  f_c1 [label = 'core\nfunction 1']
  f_c2 [label = 'core\nfunction 2']

  d_c1 -> f_c1 -> d_c2 -> f_c2 -> d_c3
}

### PUBLICATIONS
subgraph cluster_pubs {

  node [fillcolor = green]

  # function nodes
  node [shape = triangle]
  f_p1_1 [label = 'publication 1\nfunction 1']
  f_p2_1 [label = 'publication 2\nfunction 1']
  
  # data object nodes
  node [shape = circle]
  d_p1_1 [label = 'publication 1\ndata 1']
  d_p2_1 [label = 'publication 2\ndata 1']

  # plain Rmarkdown files
  node [shape = doublecircle]
  rmd_p1 [label = 'publication 1\nplain Rmd']
  rmd_p2 [label = 'publication 2\nplain Rmd']

  # rendered Rmarkdown files
  node [shape = hexagon]
  rend_p1 [label = 'rendered\npublication 1']
  rend_p2 [label = 'rendered\npublication 2']

  d_c3 -> f_p1_1 -> d_p1_1; {d_p1_1 rmd_p1} -> rend_p1
  d_c3 -> f_p2_1 -> d_p2_1; {d_p2_1 rmd_p2} -> rend_p2
}

### META
subgraph cluster_meta {

  node [fillcolor = gold]

  # function nodes
  node [shape = triangle]
  f_m1_1 [label = 'meta 1\nfunction 1']
  f_m2_1 [label = 'meta 2\nfunction 1']
  
  # data object nodes
  node [shape = circle]
  d_m1_1 [label = 'meta 1\ndata 1']
  d_m2_1 [label = 'meta 2\ndata 1']

  # workflowr Rmarkdown files
  node [shape = doublecircle]
  rmd_m1 [label = 'meta 1\nworkflowr Rmd']
  rmd_m2 [label = 'meta 2\nworkflowr Rmd']

  # rendered workflowr Rmarkdown files
  node [shape = hexagon]
  rend_m1 [label = 'rendered\nworkflowr meta 1']
  rend_m2 [label = 'rendered\nworkflowr meta 2']

  d_c1 -> f_m1_1 -> d_m1_1; {d_m1_1 rmd_m1} -> rend_m1
  d_c2 -> f_m2_1 -> d_m2_1; {d_m2_1 rmd_m2} -> rend_m2


  ### WEBSITE
  subgraph cluster_web {

    node [fillcolor = gold3]

    # workflowr Rmarkdown files
    node [shape = doublecircle]
    rmd_index [label = 'workflowr\nindex Rmd']
  
    # rendered workflowr Rmarkdown files
    node [shape = hexagon]
    rend_index [label = 'rendered\nworkflowr index']

    rmd_index -> rend_index
}
}

{rend_m1 rend_m2 rend_p1 rend_p2} -> rend_index

}
")
```

The arrows represent data flows (dependencies). These dependencies allow
`targets` to work out what is out of date and therefore requiring
re-execution conditional on any of the tracked entities being modified.

The circles represent data objects (R objects and files).

The double circles represent Rmarkdown files. `targets` treats them like
any other data object, but I have distinguished them in this diagram.

The triangles represent functions that generate or transform data.

The hexagons represent rendered Rmarkdown files.

The red nodes represent the **core** pipeline. Data is ingested and
repeatedly transformed by functions.

The green nodes represent the **publication** workflow. There can be
multiple publications derived from the core.

A publication may apply functions to core data to generate summaries for
inclusion in the publication (e.g. plots, tables).

The text of the publication is in the plain Rmarkdown file.

The publication Rmarkdown file and the data it depends on are knitted to
generate the rendered publication.

The gold nodes represent the **meta** publication workflow. The two dark
gold nodes are a special case of the meta publication workflow.

A meta publication typically applies functions to some core data to
generate summaries which inform the design reasoning for the next set of
functions in the core pipeline. (Other patterns are possible, taking
data from multiple core data objects, or even no data at all.)

The gold double circle nodes represent `workflowr` Rmarkdown files.
These contain the text of the reasoning behind the design decisions.

The `workflowr` Rmarkdown file and the data it depends on are knitted to
generate the rendered meta publication recording the reasoning behind
some design decisions.

There can be many meta publications. They are the documentation of the
design of the project.

The two dark gold nodes represent the website part of the meta
publication workflow.

The `workflowr` index Rmarkdown normally contains links to all the
rendered documents of interest (meta publications and external
publications) and is rendered to become the home page of the project
website.

# Technical details

- In https://github.com/ropensci/tarchetypes/discussions/46#discussioncomment-693001 (@wlandau)[https://github.com/wlandau] recommends
that a target tracking an Rmd document should also track the rendered output file to guard against corruption of the output.
Unfortunately, if the Rmd document is built or published with `workflowr` the rendered output file is updated, which invalidates the corresponding target in `targets`.
  - Consequently, I do not track the rendered output file for `workflowr` notebooks in the corresponding target.
    - Build the document via `tar_make()` which calls `wflow_build()`.
    -Publish the document by manually calling `wflow_publish()`.

# Useful inks

-   GitHub issue about using {targets} and {workflowr} together:
    <https://github.com/jdblischak/workflowr/issues/238>
-   GitHub repo using {targets} and {rticles} together:
    <https://github.com/b-rodrigues/covid_pred>
-   GitHub {targets} issue on tracking outdated prose in Rmarkdown
    documents and allowing sketching out a pipeline by having dummy
    target definitions:
    <https://github.com/ropensci/targets/discussions/336>
-   GitHub {tarchetypes} issue on tracking changes in Rmarkdown
    documents:
    <https://github.com/ropensci/tarchetypes/discussions/46>
-   A YouTube video on using Rmarkdown with {targets}:
    <https://www.youtube.com/watch?v=jAkNwaGRku0&feature=youtu.be>
